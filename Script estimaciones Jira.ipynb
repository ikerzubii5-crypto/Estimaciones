{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWPO4H4iOtZv"
      },
      "source": [
        "# Estimaciones JIRA (Story Points vs Horas reales)\n",
        "Este cuaderno ejecuta el análisis a partir de un CSV exportado de JIRA.\n",
        "\n",
        "**Qué genera** (en una carpeta de salida):\n",
        "- `tabla_estimaciones.html`\n",
        "- `tabla_estimaciones.png` (imagen equivalente a la tabla)\n",
        "- `estimacion_vs_real.png`\n",
        "- `tareas_dentro_fuera.png`\n",
        "- `estado_quesito.png`\n",
        "\n",
        "> Solo tienes que **subir el CSV** cuando se te pida y ejecutar las celdas en orden.\n"
      ],
      "id": "tWPO4H4iOtZv"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUYsiLrMOtZw"
      },
      "execution_count": 12,
      "outputs": [],
      "source": [
        "# Dependencias (Colab suele traerlas ya instaladas, pero lo dejamos por si acaso)\n",
        "import sys, subprocess\n",
        "\n",
        "def pip_install(pkg):\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
        "\n",
        "# Descomenta si tu entorno no trae estas libs (normalmente Colab sí)\n",
        "# pip_install(\"pandas\")\n",
        "# pip_install(\"numpy\")\n",
        "# pip_install(\"matplotlib\")\n",
        "\n",
        "import re\n",
        "import logging\n",
        "from dataclasses import dataclass, field\n",
        "from pathlib import Path\n",
        "from typing import Dict, Tuple, Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s %(message)s\")\n",
        "logger = logging.getLogger(\"estimaciones\")\n"
      ],
      "id": "YUYsiLrMOtZw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUXNJ6CrOtZx"
      },
      "source": [
        "## 1) Sube el CSV exportado de JIRA\n",
        "Pulsa ▶ en la celda y selecciona el fichero CSV."
      ],
      "id": "JUXNJ6CrOtZx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "dWN6TDxuOtZx",
        "outputId": "717b5908-8a35-4af9-acfd-56e2eb7b17da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c5c338e5-326b-4405-a22c-e60a16900fc8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c5c338e5-326b-4405-a22c-e60a16900fc8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "if not uploaded:\n",
        "    raise RuntimeError(\"No se subió ningún fichero. Vuelve a ejecutar y selecciona un CSV.\")\n",
        "\n",
        "# Nos quedamos con el primer fichero subido\n",
        "csv_name = next(iter(uploaded.keys()))\n",
        "csv_path = Path(csv_name)\n",
        "\n",
        "print(\"CSV cargado:\", csv_path)\n"
      ],
      "id": "dWN6TDxuOtZx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9n-pRkrOtZx"
      },
      "source": [
        "## 2) Código del analizador\n",
        "Esta celda define la clase `EstimacionesAnalyzer` y las funciones auxiliares para calcular la carpeta de salida por sprint."
      ],
      "id": "_9n-pRkrOtZx"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_le6GuTmOtZx"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class EstimacionesAnalyzer:\n",
        "    \"\"\"Analiza un CSV de JIRA con Story Points y Tiempo empleado.\"\"\"\n",
        "    csv_path: str | Path\n",
        "    day_hours: float = 8.0  # horas por día al parsear \"1d 2h 30m\"\n",
        "\n",
        "    # Mapa SP -> etiqueta (texto) para mostrar en tablas\n",
        "    sp_to_time: Dict[int, str] = field(default_factory=lambda: {\n",
        "        1:  \"1h\",\n",
        "        3:  \"2-4h\",\n",
        "        5:  \"6-8h (1 día)\",\n",
        "        8:  \"15-25h (2-3 días)\",\n",
        "        13: \"30-40h (4-5 días)\",\n",
        "        21: \"1 sem y media\",\n",
        "        34: \"2 sem\",\n",
        "        55: \"1 sprint (3 sem)\",\n",
        "        89: \"+1 sprint (separar)\",\n",
        "    })\n",
        "\n",
        "    # Mapa SP -> (min_horas, max_horas) para cálculo\n",
        "    sp_to_range: Dict[int, Tuple[float, float]] = field(default_factory=lambda: {\n",
        "        1:  (0, 2),\n",
        "        3:  (2, 5),\n",
        "        5:  (5, 10),\n",
        "        8:  (10, 25),\n",
        "        13: (25, 45),\n",
        "        21: (45, 70),     # ~1,5 semanas\n",
        "        34: (70, 100),    # ~2 semanas\n",
        "        55: (100, 130),   # ~1 sprint (3 semanas)\n",
        "    })\n",
        "\n",
        "    # Columnas esperadas en el CSV (después de renombrar)\n",
        "    col_story_points: str = \"Puntos de historia\"\n",
        "    col_time_spent: str = \"Tiempo empleado\"\n",
        "    col_summary: str = \"Resumen\"\n",
        "\n",
        "    df: pd.DataFrame | None = None\n",
        "    df_total: pd.DataFrame | None = None\n",
        "    df_sorted: pd.DataFrame | None = None\n",
        "\n",
        "    # -----------------------\n",
        "    # Carga y preprocesado\n",
        "    # -----------------------\n",
        "    def load(self) -> \"EstimacionesAnalyzer\":\n",
        "        \"\"\"Carga el CSV y hace limpieza básica.\"\"\"\n",
        "        self.df = pd.read_csv(self.csv_path)\n",
        "        self._rename_columns()\n",
        "        self._drop_empty_columns()\n",
        "        self._drop_unused_columns()\n",
        "        return self\n",
        "\n",
        "    def _rename_columns(self) -> None:\n",
        "        if self.df is None:\n",
        "            raise RuntimeError(\"Primero llama a load().\")\n",
        "\n",
        "        rename_map = {\n",
        "            \"Campo personalizado (Story Points)\": self.col_story_points,\n",
        "            \"Σ Tiempo empleado\": self.col_time_spent,\n",
        "        }\n",
        "        self.df = self.df.rename(columns={k: v for k, v in rename_map.items() if k in self.df.columns})\n",
        "\n",
        "    def _drop_empty_columns(self) -> None:\n",
        "        if self.df is None:\n",
        "            raise RuntimeError(\"Primero llama a load().\")\n",
        "        self.df = self.df.dropna(axis=1, how=\"all\")\n",
        "\n",
        "    def _drop_unused_columns(self) -> None:\n",
        "        \"\"\"Elimina columnas de JIRA típicamente irrelevantes (si existen).\"\"\"\n",
        "        if self.df is None:\n",
        "            raise RuntimeError(\"Primero llama a load().\")\n",
        "        cols_to_drop = [\"ID de la persona asignada\", \"Persona asignada\", \"Principal\", \"Clave principal\"]\n",
        "        existing = [c for c in cols_to_drop if c in self.df.columns]\n",
        "        if existing:\n",
        "            self.df = self.df.drop(columns=existing)\n",
        "\n",
        "    # -----------------------\n",
        "    # Parsing de tiempo\n",
        "    # -----------------------\n",
        "    def parse_time_spent(self) -> \"EstimacionesAnalyzer\":\n",
        "        \"\"\"Crea la columna 'Horas dedicadas' a partir de Tiempo empleado.\"\"\"\n",
        "        self._require_df()\n",
        "\n",
        "        if self.col_time_spent not in self.df.columns:\n",
        "            raise KeyError(f\"No existe la columna '{self.col_time_spent}' en el CSV.\")\n",
        "\n",
        "        self.df[\"Horas dedicadas\"] = self.df[self.col_time_spent].apply(self._parse_time_spent_value)\n",
        "        return self\n",
        "\n",
        "    def _parse_time_spent_value(self, x) -> float:\n",
        "        \"\"\"\n",
        "        Convierte:\n",
        "          - numérico (asumido segundos) -> horas\n",
        "          - string float (\"3.5\") -> horas\n",
        "          - \"1d 2h 30m\" -> horas (días * day_hours + horas + minutos/60)\n",
        "        \"\"\"\n",
        "        if pd.api.types.is_number(x):\n",
        "            return float(x) / 3600.0\n",
        "\n",
        "        if pd.isna(x):\n",
        "            return np.nan\n",
        "\n",
        "        s = str(x).strip()\n",
        "\n",
        "        try:\n",
        "            return float(s)\n",
        "        except ValueError:\n",
        "            pass\n",
        "\n",
        "        pattern = r\"(?:(\\d+)\\s*d)?\\s*(?:(\\d+)\\s*h)?\\s*(?:(\\d+)\\s*m)?\"\n",
        "        m = re.fullmatch(pattern, s)\n",
        "        if not m:\n",
        "            return np.nan\n",
        "\n",
        "        days = int(m.group(1)) if m.group(1) else 0\n",
        "        hours = int(m.group(2)) if m.group(2) else 0\n",
        "        minutes = int(m.group(3)) if m.group(3) else 0\n",
        "\n",
        "        return days * self.day_hours + hours + minutes / 60.0\n",
        "\n",
        "    # -----------------------\n",
        "    # Estimaciones por Story Points\n",
        "    # -----------------------\n",
        "    def add_story_points(self) -> \"EstimacionesAnalyzer\":\n",
        "        \"\"\"Normaliza story points y añade columnas de rango/etiqueta.\"\"\"\n",
        "        self._require_df()\n",
        "\n",
        "        if self.col_story_points not in self.df.columns:\n",
        "            raise KeyError(f\"No existe la columna '{self.col_story_points}' en el CSV.\")\n",
        "\n",
        "        self.df[\"story_points_int\"] = self.df[self.col_story_points].astype(\"Int64\")\n",
        "        self.df[\"Horas estimadas\"] = self.df[\"story_points_int\"].map(self.sp_to_time)\n",
        "        self.df[[\"horas_est_min\", \"horas_est_max\"]] = self.df[self.col_story_points].apply(self._sp_to_min_max)\n",
        "        return self\n",
        "\n",
        "    def _sp_to_min_max(self, sp) -> pd.Series:\n",
        "        if pd.isna(sp):\n",
        "            return pd.Series([np.nan, np.nan])\n",
        "        try:\n",
        "            sp_int = int(sp)\n",
        "        except (TypeError, ValueError):\n",
        "            return pd.Series([np.nan, np.nan])\n",
        "\n",
        "        lo, hi = self.sp_to_range.get(sp_int, (np.nan, np.nan))\n",
        "        return pd.Series([lo, hi])\n",
        "\n",
        "    def compute_within_estimate(self) -> \"EstimacionesAnalyzer\":\n",
        "        \"\"\"Añade la columna 'Bien estimado?'.\"\"\"\n",
        "        self._require_df()\n",
        "\n",
        "        def dentro_estimado(row) -> Optional[bool]:\n",
        "            sp = row.get(\"story_points_int\", pd.NA)\n",
        "            horas = row.get(\"Horas dedicadas\", np.nan)\n",
        "            if pd.isna(sp) or pd.isna(horas):\n",
        "                return np.nan\n",
        "            rango = self.sp_to_range.get(int(sp)) if pd.notna(sp) else None\n",
        "            if rango is None:\n",
        "                return np.nan\n",
        "            h_min, h_max = rango\n",
        "            return bool(h_min <= horas <= h_max)\n",
        "\n",
        "        self.df[\"Bien estimado?\"] = self.df.apply(dentro_estimado, axis=1)\n",
        "        return self\n",
        "\n",
        "    def compute_error_percent(self) -> \"EstimacionesAnalyzer\":\n",
        "        \"\"\"Añade la columna 'error (%)' (0 dentro del rango).\"\"\"\n",
        "        self._require_df()\n",
        "\n",
        "        def error_porcentual(row) -> float:\n",
        "            real = row.get(\"Horas dedicadas\", np.nan)\n",
        "            lo = row.get(\"horas_est_min\", np.nan)\n",
        "            hi = row.get(\"horas_est_max\", np.nan)\n",
        "\n",
        "            if pd.isna(real) or pd.isna(lo) or pd.isna(hi) or real == 0:\n",
        "                return np.nan\n",
        "\n",
        "            if lo <= real <= hi:\n",
        "                return 0.0\n",
        "\n",
        "            nearest = lo if abs(real - lo) <= abs(real - hi) else hi\n",
        "            return (real - nearest) / real * 100.0\n",
        "\n",
        "        self.df[\"error (%)\"] = self.df.apply(error_porcentual, axis=1)\n",
        "        return self\n",
        "\n",
        "    # -----------------------\n",
        "    # Totales y ordenación\n",
        "    # -----------------------\n",
        "    def add_total_row(self) -> \"EstimacionesAnalyzer\":\n",
        "        \"\"\"Crea df_total con una fila final de sumas en columnas numéricas.\"\"\"\n",
        "        self._require_df()\n",
        "\n",
        "        num_cols = self.df.select_dtypes(include=\"number\").columns\n",
        "        total_row = {col: \"\" for col in self.df.columns}\n",
        "\n",
        "        if self.col_summary in self.df.columns:\n",
        "            total_row[self.col_summary] = \"Total\"\n",
        "        else:\n",
        "            total_row[self.df.columns[0]] = \"Total\"\n",
        "\n",
        "        for col in num_cols:\n",
        "            total_row[col] = pd.to_numeric(self.df[col], errors=\"coerce\").sum()\n",
        "\n",
        "        self.df_total = pd.concat([self.df, pd.DataFrame([total_row])], ignore_index=True)\n",
        "        return self\n",
        "\n",
        "    def sort(self, by: str = \"Horas dedicadas\", ascending: bool = True) -> \"EstimacionesAnalyzer\":\n",
        "        \"\"\"Ordena el dataframe (usa df_total si existe).\"\"\"\n",
        "        base = self.df_total if self.df_total is not None else self.df\n",
        "        if base is None:\n",
        "            raise RuntimeError(\"No hay datos. Ejecuta load().\")\n",
        "        if by not in base.columns:\n",
        "            raise KeyError(f\"No existe la columna '{by}' para ordenar.\")\n",
        "\n",
        "        self.df_sorted = base.sort_values(by=by, ascending=ascending)\n",
        "        return self\n",
        "\n",
        "    # -----------------------\n",
        "    # Estilos y exportación\n",
        "    # -----------------------\n",
        "    @staticmethod\n",
        "    def _color_bien_estimado_bool(orig) -> str:\n",
        "        if pd.isna(orig):\n",
        "            return \"background-color: yellow; color: black; font-weight: bold\"\n",
        "        if orig is True:\n",
        "            return \"background-color: lightgreen; color: black; font-weight: bold\"\n",
        "        if orig is False:\n",
        "            return \"background-color: lightcoral; color: black; font-weight: bold\"\n",
        "        return \"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def _color_horas_estimadas(val) -> str:\n",
        "        if pd.isna(val):\n",
        "            return \"background-color: lightcoral; color: black; font-weight: bold\"\n",
        "        return \"\"\n",
        "\n",
        "    def _display_cols(self, base: pd.DataFrame) -> list[str]:\n",
        "        return [c for c in [self.col_summary, self.col_story_points, \"Horas dedicadas\",\n",
        "                            \"Horas estimadas\", \"Bien estimado?\", \"error (%)\"] if c in base.columns]\n",
        "\n",
        "    def display_df(self) -> pd.DataFrame:\n",
        "        \"\"\"DF exacto que se pinta en el HTML, con formato listo para mostrar/guardar.\"\"\"\n",
        "        base = self.df_sorted if self.df_sorted is not None else (\n",
        "            self.df_total if self.df_total is not None else self.df\n",
        "        )\n",
        "        if base is None:\n",
        "            raise RuntimeError(\"No hay datos. Ejecuta el pipeline primero.\")\n",
        "\n",
        "        cols = self._display_cols(base)\n",
        "        df_show = base[cols].copy()\n",
        "\n",
        "        numeric_cols = df_show.select_dtypes(include=\"number\").columns.tolist()\n",
        "        for c in numeric_cols:\n",
        "            if c == self.col_story_points:\n",
        "                df_show[c] = pd.to_numeric(df_show[c], errors=\"coerce\").round(0).astype(\"Int64\")\n",
        "            else:\n",
        "                df_show[c] = pd.to_numeric(df_show[c], errors=\"coerce\").round(1)\n",
        "\n",
        "        return df_show\n",
        "\n",
        "    def styled_table(self) -> \"pd.io.formats.style.Styler\":\n",
        "        df_show = self.display_df()\n",
        "\n",
        "        bien_orig = df_show[\"Bien estimado?\"].copy() if \"Bien estimado?\" in df_show.columns else None\n",
        "\n",
        "        if \"Bien estimado?\" in df_show.columns:\n",
        "            df_show[\"Bien estimado?\"] = \"\"\n",
        "\n",
        "        fmt = {c: \"{:.1f}\" for c in df_show.select_dtypes(include=\"number\").columns}\n",
        "        if self.col_story_points in fmt:\n",
        "            fmt[self.col_story_points] = \"{:.0f}\"\n",
        "\n",
        "        styler = df_show.style.format(fmt, na_rep=\"\")\n",
        "\n",
        "        if bien_orig is not None:\n",
        "            styler = styler.apply(\n",
        "                lambda col: [self._color_bien_estimado_bool(v) for v in bien_orig],\n",
        "                subset=[\"Bien estimado?\"],\n",
        "            )\n",
        "\n",
        "        if \"Horas estimadas\" in df_show.columns:\n",
        "            styler = styler.map(self._color_horas_estimadas, subset=[\"Horas estimadas\"])\n",
        "\n",
        "        return styler\n",
        "\n",
        "    def save_table_image(self, out_png: str | Path) -> None:\n",
        "        \"\"\"\n",
        "        Exporta una imagen PNG \"equivalente\" a la tabla HTML (misma info + colores).\n",
        "        No depende de navegador/selenium.\n",
        "        \"\"\"\n",
        "        base = self.df_sorted if self.df_sorted is not None else (self.df_total if self.df_total is not None else self.df)\n",
        "        if base is None:\n",
        "            raise RuntimeError(\"No hay datos. Ejecuta el pipeline primero.\")\n",
        "\n",
        "        cols = [c for c in [self.col_summary, self.col_story_points, \"Horas dedicadas\",\n",
        "                            \"Horas estimadas\", \"Bien estimado?\", \"error (%)\"] if c in base.columns]\n",
        "        df_img = base[cols].copy()\n",
        "        bien_orig = df_img[\"Bien estimado?\"].copy() if \"Bien estimado?\" in df_img.columns else None\n",
        "\n",
        "        if \"Bien estimado?\" in df_img.columns:\n",
        "            df_img[\"Bien estimado?\"] = \"\"\n",
        "\n",
        "        if \"Horas dedicadas\" in df_img.columns:\n",
        "            df_img[\"Horas dedicadas\"] = pd.to_numeric(df_img[\"Horas dedicadas\"], errors=\"coerce\").round(1)\n",
        "        if \"error (%)\" in df_img.columns:\n",
        "            df_img[\"error (%)\"] = pd.to_numeric(df_img[\"error (%)\"], errors=\"coerce\").round(1)\n",
        "\n",
        "        nrows, ncols = df_img.shape\n",
        "        fig_w = max(10, ncols * 2.2)\n",
        "        fig_h = max(2.5, nrows * 0.45)\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(fig_w, fig_h))\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "        table = ax.table(\n",
        "            cellText=df_img.astype(str).values,\n",
        "            colLabels=df_img.columns.tolist(),\n",
        "            cellLoc=\"left\",\n",
        "            loc=\"center\",\n",
        "        )\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(10)\n",
        "        table.scale(1, 1.2)\n",
        "\n",
        "        for c in range(ncols):\n",
        "            cell = table[(0, c)]\n",
        "            cell.set_text_props(weight=\"bold\")\n",
        "\n",
        "        col_idx = {name: i for i, name in enumerate(df_img.columns.tolist())}\n",
        "        bien_col = col_idx.get(\"Bien estimado?\")\n",
        "        horas_est_col = col_idx.get(\"Horas estimadas\")\n",
        "\n",
        "        for r in range(1, nrows + 1):\n",
        "            if bien_col is not None and bien_orig is not None:\n",
        "                orig = bien_orig.iloc[r - 1]\n",
        "                cell = table[(r, bien_col)]\n",
        "\n",
        "                if pd.isna(orig):\n",
        "                    cell.set_facecolor(\"yellow\")\n",
        "                    cell.set_text_props(weight=\"bold\")\n",
        "                elif orig is True:\n",
        "                    cell.set_facecolor(\"lightgreen\")\n",
        "                    cell.set_text_props(weight=\"bold\")\n",
        "                elif orig is False:\n",
        "                    cell.set_facecolor(\"lightcoral\")\n",
        "                    cell.set_text_props(weight=\"bold\")\n",
        "\n",
        "            if horas_est_col is not None:\n",
        "                orig_he = base[cols].iloc[r - 1][\"Horas estimadas\"]\n",
        "                cell = table[(r, horas_est_col)]\n",
        "                if pd.isna(orig_he) or orig_he == \"\":\n",
        "                    cell.set_facecolor(\"lightcoral\")\n",
        "                    cell.set_text_props(weight=\"bold\")\n",
        "\n",
        "        out_png = Path(out_png)\n",
        "        out_png.parent.mkdir(parents=True, exist_ok=True)\n",
        "        fig.savefig(out_png, bbox_inches=\"tight\", dpi=200)\n",
        "        plt.close(fig)\n",
        "\n",
        "    def save_outputs(self, out_dir: str | Path) -> \"EstimacionesAnalyzer\":\n",
        "        \"\"\"\n",
        "        Guarda:\n",
        "          - tabla_estimaciones.html\n",
        "          - tabla_estimaciones.png\n",
        "          - (los plots se guardan desde run_all)\n",
        "\n",
        "        IMPORTANTE: no se generan CSVs.\n",
        "        \"\"\"\n",
        "        self._require_df()\n",
        "        out = Path(out_dir)\n",
        "        out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        html = self.styled_table().to_html()\n",
        "        (out / \"tabla_estimaciones.html\").write_text(html, encoding=\"utf-8\")\n",
        "\n",
        "        self.save_table_image(out / \"tabla_estimaciones.png\")\n",
        "\n",
        "        logger.info(\"Outputs guardados en: %s\", out)\n",
        "        return self\n",
        "\n",
        "    # -----------------------\n",
        "    # Gráficos\n",
        "    # -----------------------\n",
        "    def plot_est_vs_real(self, show: bool = True, save_path: str | Path | None = None) -> None:\n",
        "        \"\"\"Bar chart: horas estimadas (punto medio) vs horas reales (media) por story point.\"\"\"\n",
        "        self._require_df()\n",
        "\n",
        "        ranges_df = (\n",
        "            pd.DataFrame.from_dict(self.sp_to_range, orient=\"index\", columns=[\"h_min\", \"h_max\"])\n",
        "            .assign(h_mid=lambda d: (d[\"h_min\"] + d[\"h_max\"]) / 2)\n",
        "        )\n",
        "        mean_hours = self.df.groupby(\"story_points_int\")[\"Horas dedicadas\"].mean()\n",
        "        merged = ranges_df.join(mean_hours).rename(columns={\"Horas dedicadas\": \"h_real\"}).dropna()\n",
        "\n",
        "        x = np.arange(len(merged))\n",
        "        plt.figure()\n",
        "        plt.bar(x - 0.15, merged[\"h_mid\"], width=0.3, label=\"Horas estimadas (medio)\")\n",
        "        plt.bar(x + 0.15, merged[\"h_real\"], width=0.3, label=\"Horas reales (media)\")\n",
        "        plt.xticks(x, merged.index)\n",
        "        plt.xlabel(\"Story points\")\n",
        "        plt.ylabel(\"Horas\")\n",
        "        plt.title(\"Estimación vs realidad por story point\")\n",
        "        plt.legend()\n",
        "        plt.grid(axis=\"y\")\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "        if show:\n",
        "            plt.show()\n",
        "        else:\n",
        "            plt.close()\n",
        "\n",
        "    def plot_within_out_counts(self, show: bool = True, save_path: str | Path | None = None) -> None:\n",
        "        \"\"\"Bar chart: conteo de tareas dentro/fuera de estimación (solo enteros).\"\"\"\n",
        "        self._require_df()\n",
        "\n",
        "        base = self.df_sorted if self.df_sorted is not None else (self.df_total if self.df_total is not None else self.df)\n",
        "        if base is None:\n",
        "            raise RuntimeError(\"No hay datos. Ejecuta el pipeline primero.\")\n",
        "        if \"Bien estimado?\" not in base.columns:\n",
        "            raise RuntimeError(\"No existe 'Bien estimado?'. Ejecuta compute_within_estimate().\")\n",
        "\n",
        "        plot_df = base.copy()\n",
        "        if self.col_summary in plot_df.columns:\n",
        "            plot_df = plot_df[plot_df[self.col_summary] != \"Total\"]\n",
        "\n",
        "        counts_raw = plot_df[\"Bien estimado?\"].value_counts(dropna=False)\n",
        "\n",
        "        def _label(v):\n",
        "            if pd.isna(v):\n",
        "                return \"Sin dato\"\n",
        "            if v is True:\n",
        "                return \"Dentro\"\n",
        "            if v is False:\n",
        "                return \"Fuera\"\n",
        "            return str(v)\n",
        "\n",
        "        counts = counts_raw.copy()\n",
        "        counts.index = [_label(v) for v in counts.index]\n",
        "        counts = counts.groupby(level=0).sum()\n",
        "\n",
        "        order = [\"Dentro\", \"Fuera\", \"Sin dato\"]\n",
        "        counts = counts.reindex(order).fillna(0).astype(int)\n",
        "\n",
        "        colors = [\"green\", \"red\", \"yellow\"]\n",
        "\n",
        "        fig, ax = plt.subplots()\n",
        "        counts.plot(kind=\"bar\", ax=ax, color=colors)\n",
        "        ax.set_title(\"Tareas dentro / fuera de la estimación\")\n",
        "        ax.set_ylabel(\"Número de tareas\")\n",
        "        ax.grid(axis=\"y\")\n",
        "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "\n",
        "        for p in ax.patches:\n",
        "            h = int(round(p.get_height()))\n",
        "            ax.annotate(\n",
        "                f\"{h}\",\n",
        "                (p.get_x() + p.get_width() / 2, p.get_height()),\n",
        "                ha=\"center\",\n",
        "                va=\"bottom\",\n",
        "                fontsize=10,\n",
        "            )\n",
        "\n",
        "        plt.xticks(rotation=0)\n",
        "\n",
        "        if save_path:\n",
        "            plt.savefig(save_path, bbox_inches=\"tight\")\n",
        "        if show:\n",
        "            plt.show()\n",
        "        else:\n",
        "            plt.close(fig)\n",
        "\n",
        "    def plot_estado_pie(\n",
        "        self,\n",
        "        show: bool = True,\n",
        "        save_path: str | Path | None = None,\n",
        "        estado_col: str = \"Estado\",\n",
        "        min_pct_label: float = 3.0,\n",
        "    ) -> None:\n",
        "        self._require_df()\n",
        "\n",
        "        if estado_col not in self.df.columns:\n",
        "            raise KeyError(f\"No existe la columna '{estado_col}' en el CSV.\")\n",
        "\n",
        "        s = self.df[estado_col].fillna(\"Sin dato\").astype(str).str.strip()\n",
        "        counts = s.value_counts()\n",
        "\n",
        "        desired_order = [\"Cerrado\", \"Validando\", \"En curso\", \"Bloqueado\", \"Abierto\", \"Sin dato\"]\n",
        "        counts = counts.reindex(desired_order + [x for x in counts.index if x not in desired_order]).dropna()\n",
        "\n",
        "        labels = counts.index.tolist()\n",
        "        values = counts.values.astype(int).tolist()\n",
        "        total = int(counts.sum())\n",
        "\n",
        "        palette = {\n",
        "            \"Cerrado\":   \"#2E7D32\",  # verde\n",
        "            \"Abierto\":   \"#0105FD\",  # azul (no hecho)\n",
        "            \"En curso\":  \"#C8E6C9\",  # verde muy claro\n",
        "            \"Validando\": \"#FB8C00\",  # naranja\n",
        "            \"Bloqueado\": \"#D32F2F\",  # rojo\n",
        "            \"Sin dato\":  \"#757575\",  # gris\n",
        "        }\n",
        "\n",
        "        fallback_cycle = iter(plt.cm.tab20.colors)\n",
        "        colors = []\n",
        "        for lab in labels:\n",
        "            colors.append(palette.get(lab, next(fallback_cycle)))\n",
        "\n",
        "        explode = []\n",
        "        for v in values:\n",
        "            pct = 100.0 * v / total if total else 0.0\n",
        "            explode.append(0.06 if pct < min_pct_label else 0.0)\n",
        "\n",
        "        def _autopct(pct: float) -> str:\n",
        "            return f\"{pct:.1f}%\" if pct >= min_pct_label else \"\"\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        wedges, *_ = ax.pie(\n",
        "            values,\n",
        "            labels=None,\n",
        "            colors=colors,\n",
        "            explode=explode,\n",
        "            autopct=_autopct,\n",
        "            startangle=90,\n",
        "            pctdistance=0.70,\n",
        "            wedgeprops={\"linewidth\": 1, \"edgecolor\": \"white\"},\n",
        "            textprops={\"fontsize\": 11},\n",
        "        )\n",
        "\n",
        "        legend_labels = [\n",
        "            f\"{lab} — {v} ({(100.0*v/total if total else 0.0):.1f}%)\"\n",
        "            for lab, v in zip(labels, values)\n",
        "        ]\n",
        "        ax.legend(\n",
        "            wedges,\n",
        "            legend_labels,\n",
        "            title=\"Estado\",\n",
        "            loc=\"center left\",\n",
        "            bbox_to_anchor=(1.02, 0.5),\n",
        "            frameon=False,\n",
        "        )\n",
        "\n",
        "        ax.set_title(\"Distribución por estado\")\n",
        "        ax.axis(\"equal\")\n",
        "        fig.tight_layout()\n",
        "\n",
        "        if save_path:\n",
        "            save_path = Path(save_path)\n",
        "            save_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "            fig.savefig(save_path, bbox_inches=\"tight\", dpi=300)\n",
        "\n",
        "        if show:\n",
        "            plt.show()\n",
        "        else:\n",
        "            plt.close(fig)\n",
        "\n",
        "    # -----------------------\n",
        "    # Pipeline completo\n",
        "    # -----------------------\n",
        "    def run_all(self, out_dir: str | Path | None = None) -> \"EstimacionesAnalyzer\":\n",
        "        \"\"\"Ejecuta el pipeline completo en el orden del notebook.\"\"\"\n",
        "        (\n",
        "            self.load()\n",
        "            .parse_time_spent()\n",
        "            .add_story_points()\n",
        "            .compute_within_estimate()\n",
        "            .compute_error_percent()\n",
        "            .add_total_row()\n",
        "            .sort(by=\"Horas dedicadas\", ascending=True)\n",
        "        )\n",
        "\n",
        "        if out_dir:\n",
        "            out = Path(out_dir)\n",
        "            out.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "            self.save_outputs(out_dir)\n",
        "\n",
        "            self.plot_est_vs_real(show=False, save_path=out / \"estimacion_vs_real.png\")\n",
        "            self.plot_within_out_counts(show=False, save_path=out / \"tareas_dentro_fuera.png\")\n",
        "            self.plot_estado_pie(show=False, save_path=out / \"estado_quesito.png\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    # -----------------------\n",
        "    # Helpers\n",
        "    # -----------------------\n",
        "    def _require_df(self) -> None:\n",
        "        if self.df is None:\n",
        "            raise RuntimeError(\"No hay dataframe cargado. Llama a load() primero.\")\n",
        "\n",
        "\n",
        "# --- Helpers para construir la ruta de salida por sprint (igual que tu script) ---\n",
        "\n",
        "SPRINT_OVERRIDES: Dict[int, Tuple[int, int, int]] = {\n",
        "    4825: (2025, 4, 2),\n",
        "    4826: (2025, 4, 3),\n",
        "    4827: (2025, 4, 4),\n",
        "    4828: (2026, 1, 1),\n",
        "}\n",
        "\n",
        "BASE_SPRINT_NUM = 4825\n",
        "BASE_YEAR, BASE_QUARTER, BASE_SPRINT_IN_QUARTER = (2025, 4, 2)\n",
        "\n",
        "SPRINTS_PER_QUARTER = 4\n",
        "QUARTERS_PER_YEAR = 4\n",
        "\n",
        "def _extract_sprint_number(csv_path: str | Path) -> int:\n",
        "    \"\"\"Extrae el primer número de 4 dígitos del nombre del CSV.\"\"\"\n",
        "    name = Path(csv_path).name\n",
        "    m = re.search(r\"(\\d{4})\", name)\n",
        "    if not m:\n",
        "        raise ValueError(f\"No se pudo extraer un sprint de 4 dígitos del nombre: {name}\")\n",
        "    return int(m.group(1))\n",
        "\n",
        "def _advance_calendar(year: int, quarter: int, sprint_in_quarter: int, delta: int) -> Tuple[int, int, int]:\n",
        "    \"\"\"\n",
        "    Avanza (o retrocede) delta sprints, asumiendo 4 sprints por trimestre y 4 trimestres por año.\n",
        "    sprint_in_quarter está en [1..4], quarter en [1..4]\n",
        "    \"\"\"\n",
        "    if quarter not in (1, 2, 3, 4):\n",
        "        raise ValueError(f\"Trimestre inválido: {quarter}\")\n",
        "    if sprint_in_quarter not in (1, 2, 3, 4):\n",
        "        raise ValueError(f\"Sprint inválido dentro del trimestre: {sprint_in_quarter}\")\n",
        "\n",
        "    base_index = (quarter - 1) * SPRINTS_PER_QUARTER + (sprint_in_quarter - 1)\n",
        "    new_index = base_index + delta\n",
        "\n",
        "    year_delta, idx_in_year = divmod(new_index, QUARTERS_PER_YEAR * SPRINTS_PER_QUARTER)\n",
        "    new_year = year + year_delta\n",
        "\n",
        "    new_quarter = (idx_in_year // SPRINTS_PER_QUARTER) + 1\n",
        "    new_sprint = (idx_in_year % SPRINTS_PER_QUARTER) + 1\n",
        "\n",
        "    return int(new_year), int(new_quarter), int(new_sprint)\n",
        "\n",
        "def _resolve_year_quarter_sprint(sprint_num: int) -> Tuple[int, int, int]:\n",
        "    \"\"\"\n",
        "    Devuelve (year, quarter, sprint_in_quarter).\n",
        "    - Primero mira overrides (casos conocidos).\n",
        "    - Si no está, calcula por desplazamiento desde BASE_SPRINT_NUM.\n",
        "    \"\"\"\n",
        "    if sprint_num in SPRINT_OVERRIDES:\n",
        "        return SPRINT_OVERRIDES[sprint_num]\n",
        "\n",
        "    delta = sprint_num - BASE_SPRINT_NUM\n",
        "    return _advance_calendar(BASE_YEAR, BASE_QUARTER, BASE_SPRINT_IN_QUARTER, delta)\n",
        "\n",
        "def _build_out_dir(base_out_dir: str | Path, csv_path: str | Path) -> Path:\n",
        "    sprint_num = _extract_sprint_number(csv_path)\n",
        "    year, quarter, sprint_n = _resolve_year_quarter_sprint(sprint_num)\n",
        "    return Path(base_out_dir) / str(year) / f\"Trimestre_{quarter}\" / f\"Sprint_{sprint_n}\"\n"
      ],
      "id": "_le6GuTmOtZx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufNzKcW8OtZy"
      },
      "source": [
        "## 3) Ejecuta el análisis\n",
        "Puedes ajustar `day_hours` (horas por día) y `BASE_OUT_DIR` (carpeta raíz de salida)."
      ],
      "id": "ufNzKcW8OtZy"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg4MB5diOtZz"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "# Ajustes\n",
        "day_hours = 8.0\n",
        "BASE_OUT_DIR = Path(\"outputs\")  # en Colab, se crea en el directorio de trabajo\n",
        "\n",
        "out_dir = _build_out_dir(BASE_OUT_DIR, csv_path)\n",
        "print(\"Out dir:\", out_dir)\n",
        "\n",
        "analyzer = EstimacionesAnalyzer(csv_path=csv_path, day_hours=day_hours).run_all(out_dir=out_dir)\n",
        "\n",
        "# Vista rápida en pantalla (lo mismo que la tabla HTML)\n",
        "df_show = analyzer.display_df()\n",
        "display(df_show)\n"
      ],
      "id": "Xg4MB5diOtZz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sKk1t5-FOtZz"
      },
      "source": [
        "## 4) Ver y descargar los resultados\n",
        "Generamos un ZIP con los ficheros y lo descargamos."
      ],
      "id": "sKk1t5-FOtZz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH2Z-X8iOtZz"
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "from pathlib import Path\n",
        "\n",
        "# out_dir ya es algo como: outputs/2025/Trimestre_4/Sprint_3\n",
        "# BASE_OUT_DIR es: outputs\n",
        "rel = out_dir.relative_to(BASE_OUT_DIR)  # 2025/Trimestre_4/Sprint_3\n",
        "\n",
        "# Crear \"Resultados.zip\" (sin extensión para make_archive)\n",
        "zip_base = out_dir.parent / \"Resultados\"  # p.ej. outputs/2025/Trimestre_4/Resultados\n",
        "zip_path = Path(shutil.make_archive(\n",
        "    base_name=str(zip_base),\n",
        "    format=\"zip\",\n",
        "    root_dir=str(BASE_OUT_DIR),\n",
        "    base_dir=str(rel)\n",
        "))\n",
        "\n",
        "print(\"ZIP creado en:\", zip_path)\n",
        "files.download(str(zip_path))\n"
      ],
      "id": "cH2Z-X8iOtZz"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9C87XlY5SNOG"
      },
      "id": "9C87XlY5SNOG",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}